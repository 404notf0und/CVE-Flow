import requests
import json
import math
import re
from bs4 import BeautifulSoup
from datetime import datetime
import codecs
import os
import random
import pandas
import configparser
from lib.sqlite3_operate import SQLite,create_table,cve_exists,cve_exists_where
from lib.utils import path,time_delta,get_ua,list2tuple_dict
from lib.seebug_crawler import seebug_headers
from lib.exploitdb_crawler import expdb_exp_add,expdb_exp_all

def cvedetails_parser(cid):
    """
    单次解析，返回cve id的exp标记
    :param url:
    :return label:
        :type:int
        :value:1不存在，2存在且无exp，3存在且有msf exp标记，4存在且有public exploit,7存在且有msf和pub
    """
    try:
        url="https://www.cvedetails.com/cve/{}/".format(cid)
        r=requests.get(url,timeout=5).text
        if re.search(r'(\d) public exploit',r):
            if re.search(r'(\d) Metasploit modules',r):
                label=7
            else:
                label=4
        elif re.search(r'(\d) Metasploit modules',r):
            label=3
        elif re.search(r'Unknown CVE ID',r):
            label=1
        else:
            label=2
        return label
    except Exception as e:
        print("[!] Error %s %s in function `cvedetails_parser`" %(url,str(e)))
        return False

def cvedetails_crawler():
    """
    从cvedetails.com爬增量exp标记
    :return exp_add:list, e.g. (cid,label,'cvedetails')
    """
    print('[+] Searching exp added from remote cve details, it will costs several minute')
    create_table(db='cvedetail',table='cvedetail_exp',key=['cve_id','label'],primary_key='cve_id')
    so,exist_cid=cve_exists(db='cvedetail',table='cvedetail_exp',key=['cve_id'])
    so1,all_cid=cve_exists(db='nvd',table='nvd_cve',key=['CVE_Items_cve_CVE_data_meta_ID','CVE_Items_publishedDate'])
    all_cid=sorted(all_cid,key=lambda x:datetime.strptime(x[1],'%Y-%m-%dT%H:%MZ'))
    all_cid=[i[0] for i in all_cid]
    add_cid=list(set(all_cid).difference(set(exist_cid))) 

    cve_add=dict()
    exp_add=dict()
    count=0
    for cid in add_cid:
        label=cvedetails_parser(cid)
        if label and label!=1:
            cve_add[cid]=(cid,label)
        if label and label in [3,4,7]:
            exp_add[cid]=(cid,label,'cvedetails')
        #print((cid,label,'cvedetails'))
    sql='replace INTO cvedetail_exp (cve_id, label) VALUES (?, ?)'
    so.executemany(sql,cve_add.values())

    return exp_add

def cvedetails_all():
    """从本地数据库中取出全部exp标记的CVE
    :return exist_exp:list, e.g. ['CVE-xxx','CVE-xxx']
    """
    print('[+] Searching all exp from local cve details database')
    so,exist_exp=cve_exists_where(db='cvedetail',table='cvedetail_exp',key=['cve_id'],where='label in (3,4,7)')
    return exist_exp

def nvd_nist_add(): # todo
    """从nvd.nist中reference source中提取当天exp增量：当天修改且exploit的CVE 中 之前无exploit的CVE 和 之前不存在的CVE
    """
    pass

def nvd_nist_all(): 
    """
    从nvd.nist中reference source中提取全部exp标记的CVE
    打标策略之一：exploit-db verified or verified？
    :return ids:list, e.g. ['CVE-xxx','CVE-xxx']
    """
    print('[+] Searching all exp from local nvd nist database')
    so=SQLite('data/nvd.db')
    sql='select CVE_Items_cve_CVE_data_meta_ID from nvd_cve where CVE_Items_cve_references_reference_data_tags like "%Exploit%"'
    r=so.query(sql)
    ids=[i[0] for i in r]
    
    return ids

def mitre_expdb_all(): # todo 存储 对比新增
    """
    从cve.mitre.org中提取CVE exp label，弥补nvd.nist中Resource中Exploit标记的不足
    更新策略：全量更新，返回全部数据
    :return cve_exp:tuple_dict, cve id mapping edb id, e.g. {'cve-id':('cve-id','edb-id')}
    """
    print('[+] Searching all exp from remote mitre expdb')
    hfile=path('../data/nvd','source-EXPLOIT-DB.html')
    if not os.path.exists(hfile):
        r=requests.get('https://cve.mitre.org/data/refs/refmap/source-EXPLOIT-DB.html')
        html=r.content
        with codecs.open(hfile,'wb') as f:
            f.write(html)

    cve_exp=dict()
    if os.path.exists(hfile):
        with codecs.open(hfile,'rb') as f:
            soup=BeautifulSoup(f,'html.parser')
            for tr in soup.find_all('tr'):
                exp_db=''
                cve=''
                for td in tr.find_all('td'):
                    t=str(td)
                    
                    if re.search(r'EXPLOIT-DB:(\d+)',t):
                        r=re.search(r'EXPLOIT-DB:(\d+)',t)
                        exp_db=r.group(1)
                    elif re.search(r'(CVE-[\d]+-[\d]+)',t):
                        r=re.findall(r'(CVE-[\d]+-[\d]+)',t)
                        cve=[]
                        for c in r:
                            cve.append(c)
                    else:
                        continue
                
                if exp_db and cve:
                    if isinstance(cve,list):
                        for c in cve:
                            cve_exp[c]=(c,exp_db)
                    else:
                        cve_exp[cve]=(cve,exp_db)
    
    return cve_exp

def mitre_expdb_add(): # todo
    """cve.mitre.org的增量：最新获取-本地已有
    """
    pass

class GitHub(object):
    def __init__(self, **config_options):
        self.__dict__.update(**config_options)
        self.session = requests.Session()
        if hasattr(self, 'api_token'):
           self.session.headers['Authorization'] = 'token %s' % self.api_token
        elif hasattr(self, 'username') and hasattr(self, 'password'):
           self.session.auth = (self.username, self.password)

    def call_to_the_api(self, *args):
        try:
            res=self.session.get(*args)
        except Exception as e:
            print("[Error] %s" %str(e))
            return 
        # do stuff with args
        return res

def single_parser(gh,items):
    """
    解析单个仓库：仓库名，描述，目录名，获取CVE和exp标记
    """
    cve=dict()
    for item in items:
        name=item['name']
        description=item['description']
        content_url=item['contents_url']
        html_url=item['html_url']
        name=re.search(r'CVE-(\d+)-(\d+)',name)
        description=re.search(r'CVE-(\d+)-(\d+)',str(description)) # description is None
        if name:
            cve[name.group(0)]=(name.group(0),html_url)
            continue
        elif description:
            cve[description.group(0)]=(description.group(0),html_url)
            continue
        elif content_url:
            r=gh.call_to_the_api(content_url)
            if r: # r is None
                content=r.text
                match=re.findall(r'(CVE-[\d]+-[\d]+)',content)
                if match:
                    match=list(set(match))
                    for i in match:
                        cve[i]=(i,html_url)

    return cve

def single_request(gh,kname='CVE exploit',page=1,per_page=50):
    """
    解析单页仓库数据，获取CVE和exp标记
    :return cve_list:list, cve id in each page by searching github.com
    """
    cve=dict()
    url="https://api.github.com/search/repositories?q={key_name}&sort=updated&order=desc&page={page}&per_page={per_page}".format(key_name=kname,page=page,per_page=per_page)
    r=gh.call_to_the_api(url)
    if r:
        content=r.text
        js=json.loads(content)
        items=js['items']
        total_count=js['total_count']

        cve_add=single_parser(gh,items)
        if cve_add:
            cve={**cve,**cve_add}
        return total_count,cve
    else:
        return False,False

def max_total_count(gh,kname='CVE exploit',page=1,per_page=50):
    """
    一次解析，返回检索结果总条数
    """
    cve_list=[]
    url="https://api.github.com/search/repositories?q={key_name}&sort=updated&order=desc&page={page}&per_page={per_page}".format(key_name=kname,page=page,per_page=per_page)
    r=gh.call_to_the_api(url)
    if r:
        content=r.text
        js=json.loads(content)
        total_count=js['total_count']
        return total_count
    else:
        print("[Error] Failed to access to api.github.com/search")
        return 

def github_exp_all():
    """
    :return exist_cid:list, cve id existed in sqlite3 from github.com
    """
    print('[+] Searching all exp from local github db')
    so,exist_cid=cve_exists(db='github',table='github_exp',key=['cve_id'])
    return exist_cid

def github_exp_add(per_page=100):
    """
    根据(多组)关键词搜索github上cve和exp标记
    更新策略：支持部分存量、增量更新
    :return cve_add:tuple_dict, cve id added in github.com
    """
    # 本地和远程对比->差集
    print('[+] Searching exp added from remote github.com')
    create_table(db='github',table='github_exp',key=['cve_id','label'],primary_key='cve_id') ## 选择sqlite3 而不是json存储的原因在易于扩展和检索
    so,exist_cid=cve_exists(db='github',table='github_exp',key=['cve_id'])
    conf=configparser.ConfigParser()
    conf.read('conf/info.conf')
    local_count=conf.get('CVE_Label','total_count')
    key_name=conf.get('CVE_Label','search_key')
    api_token=conf.get('CVE_Label','api_token')

    gh=GitHub(api_token=api_token)
    total_count=max_total_count(gh=gh,kname=key_name,per_page=per_page)

    cve_add=dict()
    if total_count:
        print("[+] Checked, Got github res total count:%s" %total_count)
        add_count=total_count-int(local_count) # todo: if add_count<per_page
        if add_count>1000:
            add_count=1000
        
        print("[+] local res:%s,total res:%s,add res:%s" %(local_count,total_count,add_count))
        # 补全差集
        page_count=math.ceil(add_count/per_page)
        if page_count>0:
            for page in range(1,page_count+1):
                t,c=single_request(gh=gh,kname=key_name,per_page=per_page,page=page)
                if t and c:
                    cl=list(c.values())
                    for i in cl:
                        if i[0] in exist_cid:
                            del c[i[0]]
                else:
                    print("[!] Error in call_to_the_api")
                if c:
                    print("[+] Github CVE Added:%s" %c)
                    cve_add={**cve_add,**c}
        else:
            print("[!] Github updated not found ")

        # 插入sqlite3
        if page_count>0:
            sql='replace INTO github_exp (cve_id, label) VALUES (?, ?)'
            so.executemany(sql,cve_add.values())
            conf.set('CVE_Label','total_count',str(total_count))
            with open('conf/info.conf', 'w') as configfile:
                conf.write(configfile)
        else:
            pass
    else:
        print("[Error] Failed to get github total count")
    
    return cve_add

def seebug_page_parser(url,headers):
    """
    解析seebug单页，获取CVE exp label,返回多条数据
    :return cve_page:tuple_dict, consists of (ssv,date,title,cid,label)
    """
    r=requests.get(url,headers=headers)
    soup=BeautifulSoup(r.content,'html.parser')
    cve_page=dict()
    cve_exp_page=dict()
    for tr in soup.find_all('tr'):
        if re.search(r'SSV-(\d)+',str(tr)):
            tds=[td for td in tr.find_all('td')]
            ssv=tds[0].text
            date=tds[1].text
            title=tds[3].text
            status=tds[4].find_all('i')
            cve_id=re.search(r'(CVE-[\d]+-[\d]+)',str(status[0]))
            if cve_id:
                cid=cve_id.group(0)
                if " ".join(status[1].get('class'))=='fa fa-rocket text-muted ':
                    label=0
                elif " ".join(status[1].get('class'))=='fa fa-rocket ':
                    label=1
                    cve_exp_page[ssv]=(ssv,date,title,cid,label)
                else:
                    print("[!] WARNING poc_value is not 0 or 1")
            else:
                cid=''
                label=''
            cve_page[ssv]=(ssv,date,title,cid,label)
    return cve_page,cve_exp_page

def seebug_max_page(url='https://www.seebug.org/vuldb/vulnerabilities'):
    """
    获取seebug漏洞数据的最大页面数
    :return max_page:
        :type:int
        :value:N
    :return headers:
        :type:dict
        :value:浏览器头
    """
    headers=seebug_headers(url)
    if headers:
        print("[+] Bypassed Seebug Anti-Crawler")
    else:
        print("[!] Failed to Bypass Seebug Anti-Crawler")
    r=requests.get(url,headers=headers)
    regex=re.compile(r'page=(\d+)')
    num=re.findall(regex,r.text)
    num=[int(i) for i in num]
    max_page=max(num)
    print("[+] Got seebug vul max page:%d" %max_page)
    return max_page,headers

def seebug_exp_add():
    """
    爬取seebug全部ssv数据，返回增量cve exp数据
    :return seebug_exp_add:tuple_dict, cve added with exp data in seebug.org, e.g. {'SSV-18407': ('SSV-18407', '2002-05-19', 'psyBNC <= 2.3 Denial of Service Exploit', 'CVE-2002-0741', 1)}
    }
    """
    print('[+] Searching exp added from remote seebug.org')
    create_table(db='seebug',table='seebug_exp',key=['ssv','date','title','cid','label'],primary_key='ssv')
    so,exist_sid=cve_exists(db='seebug',table='seebug_exp',key=['ssv'])
    max_page,headers=seebug_max_page()
    # 对比本地数据和远程第一页数据
    seebug_ssv_add=dict()
    seebug_cve_exp_add=dict()
    for page in range(1,max_page):
        print("[+] Crawling seebug vul page:%d" %page)
        et=0
        vul_url='https://www.seebug.org/vuldb/vulnerabilities?page={}'.format(str(page))
        ssv_page,exp_page=seebug_page_parser(url=vul_url,headers=headers)
        # 判断单页和本地数据重复的数量
        ssv=list(ssv_page.values())
        for i in ssv:
            if i[0] in exist_sid:
                et=et+1
                del ssv_page[i[0]]
                if i[0] in list(exp_page.values()):
                    del exp_page[i[0]]
        
        # 判断是否需要插入数据库
        if et<20:
            seebug_ssv_add={**seebug_ssv_add,**ssv_page}
        else:
            pass
        seebug_cve_exp_add={**seebug_cve_exp_add,**exp_page}

        # 判断是否退出
        if et>0: 
            break
        else:
            pass
    if seebug_ssv_add:
        sql='replace INTO seebug_exp (ssv,date,title,cid,label) VALUES (?, ?, ?, ?, ?)'
        so.executemany(sql,seebug_ssv_add.values())
    else:
        print("[!] Seebug updated not found")
    print('[+] Add ssv:%s' %seebug_cve_exp_add)
    return seebug_cve_exp_add

def seebug_exp_all():
    """
    从本地数据库中提取seebug.com所有有exp标记的cve
    :return exp_all:list, the whole cve id list with exp label from exploit-db.com, e.g. ['CVE-2020-11753', 'CVE-2019-8449']
    """
    print('[+] Searching all exp from local seebug db')
    exp_all=[]
    so,exist_cid=cve_exists_where(db='seebug',table='seebug_exp',key=['cid'],where='label=1')

    return exp_all

def securityfocus_exp():
    """
    security_focus exp label
    """
def symantic_exp():
    """
    symantic exp label
    """
def cve_in_the_wild():
    """
    cve exp label in the wild
    """

def exp_init(label_init):
    if label_init=='True':
        cvedetails_crawler()

def exp_add(token,count,header):
    """
    第三方数据源标记的exp每次增量
    :return day_exp_add:tuple_dict
    """
    day_exp_add=dict()
    a4=expdb_exp_add()
    if header:
        a5=seebug_exp_add()
        day_exp_add={**a4,**a5}
    if token and count:
        a6=github_exp_add()
        day_exp_add={**a4,**a6}

    return day_exp_add

def exp_all(token,count,header):
    """
    第三方数据源标记的exp所有数据
    :return all_exp:list
    """
    all_exp=[]
    l1=cvedetails_all()
    l2=nvd_nist_all()
    l3=list(mitre_expdb_all().keys())
    l4=expdb_exp_all()
    all_exp=l1+l2+l3+l4
    if header:
        l5=seebug_exp_all()
        all_exp=all_exp+l5
    if token and count:
        l6=github_exp_all()
        all_exp=all_exp+l6

    return all_exp

if __name__=='__main__':
    pass


    
    
    


