import requests
import json
import math
import re
from bs4 import BeautifulSoup
import codecs
import os
import random
from multiprocessing import Process,Pool
import pandas
import configparser
from sqlite3_operate import SQLite,create_table
from utils import path,time_delta,get_ua,list2tuple_dict
from seebug_crawler import seebug_headers

def cve_details_parser(url):
    """
    单次解析，返回cve id的exp标记
    :param url:
    :return label:
        :type:int
        :value:1不存在，2存在且无exp，3存在且有msf exp标记，4存在且有public exploit,7存在且有msf和pub
    """
    try:
        r=requests.get(url,timeout=5).text
        if re.search(r'(\d) public exploit',r):
            if re.search(r'(\d) Metasploit modules',r):
                label=7
            else:
                label=4
        elif re.search(r'(\d) Metasploit modules',r):
            label=3
        elif re.search(r'Unknown CVE ID',r):
            label=1
        else:
            label=2
        return label
    except Exception as e:
        print("[!] Error %s %s in function `cve_details_parser`" %(url,str(e)))
        return False

def cve_exists(db='nvd',table='nvd_cve',key='CVE_Items_cve_CVE_data_meta_ID'):
    """
    取本地数据库已有的CVE id等单字段
    :return exist_cid:
        :type:list
        :value:['1','2','3']
    """
    so=SQLite('../data/{db}.db'.format(db=db))
    sql='select {key} from {table}'.format(table=table,key=key)
    exist_cid=so.query(sql)
    if exist_cid:
        exist_cid=[i[0] for i in exist_cid]
    else:
        exist_cid=[]
    
    return so,exist_cid

def cve_details_exp():
    """
    从cvedetails.com爬cve详情和exp label:public/msf
    """
    create_table(db='cvedetail',table='cvedetail_exp',key=['cve_id','label'],primary_key='cve_id')
    so,exist_cid=cve_exists(db='cvedetail',table='cvedetail_exp',key='cve_id')
    so1,all_cid=cve_exists(db='nvd',table='nvd_cve',key='CVE_Items_cve_CVE_data_meta_ID')
    add_cid=list(set(all_cid)^set(exist_cid))
    
    cve_exp=dict()
    for cid in add_cid:
        url="https://www.cvedetails.com/cve/{}/".format(cid)
        label=cve_details_parser(url)
        print(url,label)
        if label:
            cve_exp[cid]=(cid,label)
    sql='replace INTO cvedetail_exp (cve_id, label) VALUES (?, ?)'
    so.executemany(sql,cve_exp.values())
    return 'cvedetails.com',cve_exp

def nvd_nist_exp():
    """
    从nvd.nist中reference source中提取CVE exp label
    打标策略之一：exploit-db verified or verified
    """
    so=SQLite('../data/nvd.db')
    sql='select CVE_Items_cve_CVE_data_meta_ID from nvd_cve where CVE_Items_cve_references_reference_data_tags like "%Exploit%"'
    r=so.query(sql)
    ids=[i[0] for i in r]

    cve_exp=dict()
    for cid in ids:
        url='https://nvd.nist.gov/vuln/detail/{}'.format(cid)
        cve_exp[cid]=url
    
    return 'nvd.nist.gov',cve_exp

def mitre_expdb_exp():
    """
    从cve.mitre.org中提取CVE exp label，弥补nvd.nist中Resource中Exploit标记的不足
    更新策略：全量更新，返回全部数据
    :return cve_exp:
        :type:dict
        :value:{'cve-id':'edb-id'}
    """
    hfile=path('../data/nvd',time_delta()+'source-EXPLOIT-DB.html')
    if not os.path.exists(hfile):
        r=requests.get('https://cve.mitre.org/data/refs/refmap/source-EXPLOIT-DB.html')
        html=r.content
        with codecs.open(hfile,'wb') as f:
            f.write(html)

    cve_exp=dict()
    if os.path.exists(hfile):
        with codecs.open(hfile,'rb') as f:
            soup=BeautifulSoup(f,'html.parser')
            for tr in soup.find_all('tr'):
                exp_db=''
                cve=''
                for td in tr.find_all('td'):
                    t=str(td)
                    
                    if re.search(r'EXPLOIT-DB:(\d+)',t):
                        r=re.search(r'EXPLOIT-DB:(\d+)',t)
                        exp_db=r.group(1)
                    elif re.search(r'(CVE-[\d]+-[\d]+)',t):
                        r=re.findall(r'(CVE-[\d]+-[\d]+)',t)
                        cve=[]
                        for c in r:
                            cve.append(c)
                    else:
                        continue
                
                if exp_db and cve:
                    if isinstance(cve,list):
                        for c in cve:
                            cve_exp[c]=exp_db
                    else:
                        cve_exp[cve]=exp_db
    
    return 'cve.mitre.org',cve_exp

def expdb_parser(eid):
    """
    单次解析，返回单条数据
    :param eid:
    :return exp_values:
        :type:dict
        :value:{'EDB-ID:': '37074', 'CVE:': '2015-4039;2015-4038', 'Author:': 'Panagiotis Vagenas', 'Type:': 'webapps', 'Platform:': 'PHP', 'Date:': '2015-05-21'}:
    """
    exp_values=dict()
    url='https://www.exploit-db.com/exploits/'+str(eid)
    r=requests.get(url,headers={'User-Agent':get_ua()},timeout=10)
    html=r.content
    if r.status_code==200 and b'404 Page Not Found' not in html:
        soup=BeautifulSoup(html,'html.parser')
        for div in soup.find_all('div',class_='col-6 text-center'):
            exp_value=list(div.stripped_strings)
            if len(exp_value)>=2:
                exp_values[exp_value[0]]=";".join(exp_value[1:])
            else:
                exp_values[exp_value[0]]=''
        
        return exp_values
    else:
        return False

def offensive_download():
    try:
        url='https://raw.githubusercontent.com/offensive-security/exploitdb/master/files_exploits.csv'
        r=requests.get(url)
        with codecs.open('../data/exploit-db/offensive_expfile.csv','wb') as f:
            f.write(r.content)
        print("[+] DOWNLOAD NEW EXPLOIT-DB")
    except Exception as e:
        print("[!] DOWNLOAD %s error" %url)

def expdb_exists():
    """
    从offensive Security github file exploits取最新的全量edb-id
    """
    offensive_download()
    if os.path.exists('../data/exploit-db/offensive_expfile.csv'):
        exps=pandas.read_csv('../data/exploit-db/offensive_expfile.csv')
        return list(exps['id'].values)
    else:
        return False

def expdb_exp(batch=False,batch_size=10):
    """
    从exploit-db.com中提取CVE exp label，弥补不足
    更新策略：增量覆盖
    """
    create_table(db='exp2',table='expdb',key=['edb_id','cve_id','author','type','platform','date'],primary_key='edb_id')
    so,exist_eid=cve_exists(db='exp2',table='expdb',key='edb_id')
    all_eid=expdb_exists()
    all_eid=[str(i) for i in all_eid]
    add_eid=list(set(all_eid)^set(exist_eid))
    print(add_eid)
    j=0
    cve_exp=dict()
    for eid in add_eid:
        try:
            exp_values=expdb_parser(eid)
            if exp_values:
                cve_exp[eid]=tuple(exp_values.values())
                print(cve_exp)
                j=j+1
                if batch:
                    if j%batch_size==0: ### todo
                        sql='replace INTO expdb (edb_id, cve_id, author, type, platform, date) VALUES (?, ?, ?, ?, ?, ?)'
                        so.executemany(sql,cve_exp.values())
                else:
                    sql='replace INTO expdb (edb_id, cve_id, author, type, platform, date) VALUES (?, ?, ?, ?, ?, ?)'
                    so.execute(sql,tuple(exp_values.values()))

            else:
                print("[!] exp-values Not Found")

        except Exception as e:
            print("[!] DOWNLOAD ERROR %s error:%s" %(eid,repr(e)))
        
    so.close()
  
class GitHub(object):
    def __init__(self, **config_options):
        self.__dict__.update(**config_options)
        self.session = requests.Session()
        if hasattr(self, 'api_token'):
           self.session.headers['Authorization'] = 'token %s' % self.api_token
        elif hasattr(self, 'username') and hasattr(self, 'password'):
           self.session.auth = (self.username, self.password)

    def call_to_the_api(self, *args):
        try:
            res=self.session.get(*args)
        except Exception as e:
            return 
        # do stuff with args
        return res

def single_parser(gh,items):
    """
    解析单个仓库：仓库名，描述，目录名，获取CVE和exp标记
    """
    cve_list=[]
    for item in items:
        name=item['name']
        description=item['description']
        content_url=item['contents_url']
        name=re.search(r'CVE-(\d+)-(\d+)',name)
        description=re.search(r'CVE-(\d+)-(\d+)',description)
        if name:
            cve_list.append(name.group(0))
            continue
        elif description:
            cve_list.append(description.group(0))
            continue
        elif content_url:
            r=gh.call_to_the_api(content_url)
            content=r.text
            match=re.findall(r'(CVE-[\d]+-[\d]+)',content)
            if match:
                match=list(set(match))
                cve_list.extend(match)

    cve_list=list(set(cve_list))
    return cve_list

def single_request(gh,kname='CVE exploit',page=1,per_page=50):
    """
    解析单页仓库数据，获取CVE和exp标记
    """
    cve_list=[]
    url="https://api.github.com/search/repositories?q={key_name}&sort=updated&order=desc&page={page}&per_page={per_page}".format(key_name=kname,page=page,per_page=per_page)
    r=gh.call_to_the_api(url)
    if r:
        content=r.text
        js=json.loads(content)
        items=js['items']
        cve_list.extend(single_parser(gh,items))

        total_count=js['total_count']

        return total_count,cve_list
    else:
        return False,False

def max_total_count(gh,kname='CVE exploit',page=1,per_page=50):
    """
    一次解析，返回检索结果总条数
    """
    cve_list=[]
    url="https://api.github.com/search/repositories?q={key_name}&sort=updated&order=desc&page={page}&per_page={per_page}".format(key_name=kname,page=page,per_page=per_page)
    r=gh.call_to_the_api(url)
    if r:
        content=r.text
        js=json.loads(content)
        total_count=js['total_count']

        return total_count
    else:
        return 

def github_exp(api_token,per_page=100):
    """
    根据(多组)关键词搜索github上cve和exp标记
    更新策略：支持存量和增量更新
    """
    # 本地和远程对比->差集
    create_table(db='github',table='github_exp',key=['cve_id','label'],primary_key='cve_id') ## 选择sqlite3 而不是json存储的原因在易于扩展和检索
    so,exist_cid=cve_exists(db='github',table='github_exp',key='cve_id')

    conf=configparser.ConfigParser()
    conf.read('conf/info.conf')
    local_count=conf.get('CVE_Label','total_count')
    key_name=conf.get('CVE_Label','search_key')

    gh=GitHub(api_token=api_token)
    total_count=max_total_count(gh=gh,kname=key_name,per_page=per_page)
    cve_list=[]
    if total_count:
        if total_count>1000:
            total_count=1000

        add_count=total_count-int(local_count)
        print("local num:%s,total num:%s,add num:%s" %(local_count,total_count,add_count))
        # 补全差集
        page_count=math.ceil(add_count/per_page)
        if page_count>0:
            for page in range(page_count,-1,-1):
                t,c=single_request(gh=gh,kname=key_name,per_page=per_page,page=page)
                if t:
                    print(c)
                    cve_list.extend(c)
                else:
                    print("[!] Error in call_to_the_api")
        else:
            print("[!] WARNING:No Updated in function github_cve")

        # 插入sqlite3
        if page_count>0:
            cve_tuple=list2tuple_dict(cve_list,label=1)
            sql='replace INTO github_exp (cve_id, label) VALUES (?, ?)'
            so.executemany(sql,cve_tuple.values())
            conf.set('CVE_Label','total_count',str(total_count))
            with open('conf/info.conf', 'w') as configfile:
                conf.write(configfile)
        else:
            pass
    else:
        print("[!] Error in call_to_the_api")
        return 
    return cve_list

def seebug_page_parser(url,headers):
    """
    解析seebug单页，获取CVE exp label,返回多条数据
    :return cve_page:
        :type:dict
        :value:{'cve_id1':0,'cve_id2':1,'cve_idN':0 or 1}
    """
    r=requests.get(url,headers=headers)
    soup=BeautifulSoup(r.content,'html.parser')
    cve_page=dict()
    for td_date in soup.find_all('td',class_='text-center datetime hidden-sm hidden-xs'):
        date=td_date.text
        td_status=td_date.find_next('td',class_='text-center hidden-sm hidden-xs ')
        i=td_status.find_all('i')[0]
        cve_id=re.search(r'(CVE-[\d]+-[\d]+)',str(i))
        if cve_id:
            cid=cve_id.group(0)
            if " ".join(td_status.find_all('i')[1].get('class'))=='fa fa-rocket text-muted ':
                label=0
            elif " ".join(td_status.find_all('i')[1].get('class'))=='fa fa-rocket ':
                label=1
            else:
                print("[!] WARNING poc_value is not 0 or 1")
            cve_page[cid]=(cid,label,date)
        else:
            # 非cve的漏洞
            pass
    return cve_page

def seebug_max_page(url='https://www.seebug.org/vuldb/vulnerabilities'):
    """
    获取seebug漏洞数据的最大页面数
    :return max_page:
        :type:int
        :value:N
    :return headers:
        :type:dict
        :value:浏览器头
    """
    headers=seebug_headers(url)
    r=requests.get(url,headers=headers)
    regex=re.compile(r'page=(\d+)')
    num=re.findall(regex,r.text)
    num=[int(i) for i in num]
    max_page=max(num)
    print("[+] Got max page:%d" %max_page)
    return max_page,headers

def seebug_exp(stock=True):
    """
    爬取seebug全部cve数据
    :return source:
        :type:str
        :value:'seebug'
    :return cve_seebug:
        :type:dict
        :value:seebug全部cve数据，形如{'CVE-2020-0001':0}
    """
    create_table(db='seebug',table='seebug_exp',key=['cve_id','label','date'],primary_key='cve_id')
    so,exist_cid=cve_exists(db='seebug',table='seebug_exp',key='cve_id')
    max_page,headers=seebug_max_page()
    cve_seebug=dict()
    if stock:
        for i in range(1,max_page):
            vul_url='https://www.seebug.org/vuldb/vulnerabilities?page={}'.format(str(i))
            cve_page=seebug_page_parser(url=vul_url,headers=headers)
            print("[+] Got page:%d" %(i))
            cve_seebug={**cve_seebug,**cve_page}
        sql='replace INTO seebug_exp (cve_id, label, date) VALUES (?, ?, ?)'
        so.executemany(sql,cve_seebug.values())
    else:
        page=1
        et=0
        while(page>0):
            vul_url='https://www.seebug.org/vuldb/vulnerabilities?page={}'.format(str(page))
            cve_page=seebug_page_parser(url=vul_url,headers=headers)
            for i in cve_page.values():
                if i[0] in exist_cid:
                    et=et+1
            if et>0:
                sql='replace INTO seebug_exp (cve_id, label, date) VALUES (?, ?, ?)'
                so.executemany(sql,cve_page.values())
                cve_seebug={**cve_seebug,**cve_page}
                break
            else:
                page=page+1

    return 'seebug',cve_seebug

def securityfocus_exp():
    """
    security_focus exp label
    """
def symantic_exp():
    """
    symantic exp label
    """

if __name__=='__main__':
    #b,nexp=nvd_nist_exp()
    #c,mexp=mitre_expdb_exp()
    #print(set(list(mitre_expdb_exp()[1].keys()))^set(list(nvd_nist_exp()[1].keys())))

    #expdb_exp() 

    #cve_details_exp()
    
    # github:res/code/commits/issues->cve exp label and github link
    #cve_list=github_exp(api_token='your_github_token')
    #print(cve_list)

    # other vul db, such as seebug, 0day.today etc.
    #print(seebug_exp(stock=False))

    # SecurityFocus

    # in the wild
    pass


    
    
    


