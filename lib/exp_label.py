import requests
import json
import math
import re
from bs4 import BeautifulSoup
from datetime import datetime
import codecs
import os
import random
import pandas
import configparser
from lib.sqlite3_operate import SQLite,create_table,cve_exists,cve_exists_where,cve_query_where
from lib.utils import path,time_delta,get_ua,list2tuple_dict
from lib.seebug_crawler import seebug_headers
from lib.exploitdb_crawler import expdb_exp_add,expdb_exp_all

def cvedetails_parser(cid):
    """
    单次解析，返回cve id的exp标记
    :param url:
    :return label:
        :type:int
        :value:0表示不存在 或 存在且无exp，1表示有msf_exploit标记 或 有public_exploit标记
    """
    try:
        url="https://www.cvedetails.com/cve/{}/".format(cid)
        r=requests.get(url,timeout=5).text
        if re.search(r'(\d) public exploit',r) or re.search(r'(\d) Metasploit modules',r):
            label=1
        else:
            label=0
        return label
    except Exception as e:
        print("[!] Error %s %s in function `cvedetails_parser`" %(url,str(e)))
        return False

def cvedetails_crawler():
    """
    从cvedetails.com爬exp标记
    :return exp_add:tuple_dict, e.g. (cid,label,'cvedetails')
    """
    create_table(db='exp',table='cvedetails',key=['cve_id','label'],primary_key='cve_id')
    so,exist_cid=cve_exists(db='exp',table='cvedetails',key=['cve_id'])
    so1,all_cid=cve_exists(db='cve',table='nvd',key=['CVE_Items_cve_CVE_data_meta_ID'])
    add_cid=list(set(all_cid).difference(set(exist_cid))) 

    cve_add=dict()
    exp_add=dict()
    count=0
    for cid in add_cid:
        label=cvedetails_parser(cid)
        if label==1:
            cve_add[cid]=(cid,label)
            exp_add[cid]=(cid,label,'cvedetails')
        print((cid,label))
    sql='replace INTO cvedetails (cve_id, label) VALUES (?, ?)'
    so.executemany(sql,cve_add.values())

    print('[+] Searched exp added from remote cve details, it will costs several minute')
    return exp_add

def cvedetails_all():
    """从本地数据库中取出全部exp标记的CVE
    :return exist_exp:list, e.g. ['CVE-xxx','CVE-xxx']
    """
    so,exist_exp=cve_exists_where(db='exp',table='cvedetails',key=['cve_id'],where='label in (3,4,7)')
    print('[+] Searched all exp from local cve details database')
    return exist_exp

def nvd_nist_add(): # todo
    """从nvd.nist中reference source中提取当天exp增量：当天修改且exploit的CVE 中 之前无exploit的CVE 和 之前不存在的CVE
    """
    pass

def nvd_nist_all(): 
    """
    从nvd.nist中reference source中提取全部exp标记的CVE
    打标策略之一：exploit-db verified or verified？
    :return ids:list, e.g. ['CVE-xxx','CVE-xxx']
    """
    so=SQLite('data/cve.db')
    sql='select CVE_Items_cve_CVE_data_meta_ID from nvd where CVE_Items_cve_references_reference_data_tags like "%Exploit%"'
    r=so.query(sql)
    ids=[i[0] for i in r]
    print('[+] Searched all exp from local nvd nist database')
    
    return ids

def mitre_expdb_all(reparse=False): # todo 存储 对比新增
    """
    从cve.mitre.org中提取CVE exp label，弥补nvd.nist中Resource中Exploit标记的不足
    更新策略：全量更新，返回全部数据
    :return cve_exp:tuple_dict, cve id mapping edb id, e.g. {'cve-id':('cve-id','edb-id')}
    """
    hfile=path('../data/nvd','source-EXPLOIT-DB.html')
    if reparse==True:
        os.remove(hfile)
    else:
        pass
    if not os.path.exists(hfile):
        r=requests.get('https://cve.mitre.org/data/refs/refmap/source-EXPLOIT-DB.html')
        html=r.content
        with codecs.open(hfile,'wb') as f:
            f.write(html)
    else:
        pass
    cve_exp=dict()
    if os.path.exists(hfile):
        with codecs.open(hfile,'rb') as f:
            soup=BeautifulSoup(f,'html.parser')
            for tr in soup.find_all('tr'):
                exp_db=''
                cve=''
                for td in tr.find_all('td'):
                    t=str(td)
                    
                    if re.search(r'EXPLOIT-DB:(\d+)',t):
                        r=re.search(r'EXPLOIT-DB:(\d+)',t)
                        exp_db=r.group(1)
                    elif re.search(r'(CVE-[\d]+-[\d]+)',t):
                        r=re.findall(r'(CVE-[\d]+-[\d]+)',t)
                        cve=[]
                        for c in r:
                            cve.append(c)
                    else:
                        continue
                
                if exp_db and cve:
                    if isinstance(cve,list):
                        for c in cve:
                            cve_exp[c]=(c,exp_db)
                    else:
                        cve_exp[cve]=(cve,exp_db)
    print('[+] Searched all exp from remote mitre expdb')
    return cve_exp

def mitre_expdb_add(): # todo
    """cve.mitre.org的增量：最新获取-本地已有
    """
    pass

class GitHub(object):
    def __init__(self, **config_options):
        self.__dict__.update(**config_options)
        self.session = requests.Session()
        if hasattr(self, 'api_token'):
           self.session.headers['Authorization'] = 'token %s' % self.api_token
        elif hasattr(self, 'username') and hasattr(self, 'password'):
           self.session.auth = (self.username, self.password)

    def call_to_the_api(self, *args):
        try:
            res=self.session.get(*args)
        except Exception as e:
            print("[Error] %s" %str(e))
            return 
        # do stuff with args
        return res

def single_parser(gh,items):
    """
    解析单个仓库：仓库名，描述，目录名，获取CVE, updated_at, exp url
    """
    cve=dict()
    for item in items:
        name=item['name']
        html_url=item['html_url']
        description=item['description']
        content_url=item['contents_url']
        updated_at=item['updated_at']
        name=re.search(r'CVE-(\d+)-(\d+)',name)
        description=re.search(r'CVE-(\d+)-(\d+)',str(description)) # description is None
        if name:
            cve[name.group(0)]=(name.group(0),updated_at,html_url)
            continue
        elif description:
            cve[description.group(0)]=(description.group(0),updated_at,html_url)
            continue
        elif content_url:
            r=gh.call_to_the_api(content_url)
            if r: # r is None
                content=r.text
                match=re.findall(r'(CVE-[\d]+-[\d]+)',content)
                if match:
                    match=list(set(match))
                    for i in match:
                        cve[i]=(i,updated_at,html_url)

    return cve

def single_request(gh,kname='CVE exploit',page=1,per_page=50):
    """
    解析单页仓库数据，获取CVE和exp标记
    :return cve_list:list, cve id in each page by searching github.com
    """
    cve=dict()
    url="https://api.github.com/search/repositories?q={key_name}&sort=updated&order=desc&page={page}&per_page={per_page}".format(key_name=kname,page=page,per_page=per_page)
    r=gh.call_to_the_api(url)
    if r:
        content=r.text
        js=json.loads(content)
        items=js['items']
        total_count=js['total_count']

        cve_add=single_parser(gh,items)
        if cve_add:
            cve={**cve,**cve_add}
        return total_count,cve
    else:
        return False,False

def max_total_count(gh,kname='CVE exploit',page=1,per_page=50):
    """
    一次解析，返回检索结果总条数
    """
    cve_list=[]
    url="https://api.github.com/search/repositories?q={key_name}&sort=updated&order=desc&page={page}&per_page={per_page}".format(key_name=kname,page=page,per_page=per_page)
    r=gh.call_to_the_api(url)
    if r:
        content=r.text
        js=json.loads(content)
        total_count=js['total_count']
        return total_count
    else:
        print("[Error] Failed to access to api.github.com/search")
        return 

def github_exp_all():
    """
    :return exist_cid:list, cve id existed in sqlite3 from github.com
    """
    so,exist_cid=cve_exists(db='exp',table='github',key=['cve_id'])
    print('[+] Searched all exp from local github db')
    return exist_cid

def github_exp_add(per_page=100):
    """
    根据(多组)关键词搜索github上cve和exp标记
    更新策略：支持部分存量、增量更新
    :return cve_add:tuple_dict, cve id added in github.com
    """
    # 本地和远程对比->差集
    create_table(db='exp',table='github',key=['cve_id','exp_publishedtime','label'],primary_key='cve_id') ## 选择sqlite3 而不是json存储的原因在易于扩展和检索
    so,exist_cid=cve_exists(db='exp',table='github',key=['cve_id'])
    conf=configparser.ConfigParser()
    conf.read('conf/info.conf')
    local_count=conf.get('CVE_Label','total_count')
    key_name=conf.get('CVE_Label','search_key')
    api_token=conf.get('CVE_Label','api_token')

    gh=GitHub(api_token=api_token)
    total_count=max_total_count(gh=gh,kname=key_name,per_page=per_page)

    cve_add=dict()
    if total_count:
        print("[+] Checked, Got github res total count:%s" %total_count)
        add_count=total_count-int(local_count) # todo: if add_count<per_page
        if add_count>1000:
            add_count=1000
        
        print("[+] local res:%s,total res:%s,add res:%s" %(local_count,total_count,add_count))
        # 补全差集
        page_count=math.ceil(add_count/per_page)
        if page_count>0:
            for page in range(1,page_count+1):
                t,c=single_request(gh=gh,kname=key_name,per_page=per_page,page=page)
                if t and c:
                    cl=list(c.values())
                    for i in cl:
                        if i[0] in exist_cid:
                            del c[i[0]]
                else:
                    print("[!] Error in call_to_the_api")
                if c:
                    #print("[+] Github CVE Added:%s" %c)
                    cve_add={**cve_add,**c}
        else:
            print("[!] Github updated not found ")

        # 插入sqlite3
        if page_count>0:
            sql='replace INTO github (cve_id,exp_publishedtime,label) VALUES (?, ?, ?)'
            so.executemany(sql,cve_add.values())
            conf.set('CVE_Label','total_count',str(total_count))
            with open('conf/info.conf', 'w') as configfile:
                conf.write(configfile)
        else:
            pass
    else:
        print("[Error] Failed to get github total count")
    print('[+] Searched exp added from remote github.com')
    return cve_add

def seebug_page_parser(url,headers):
    """
    解析seebug单页，获取CVE exp label,返回多条数据
    :return cve_page:tuple_dict, consists of (ssv,date,title,cid,label)
    """
    r=requests.get(url,headers=headers)
    soup=BeautifulSoup(r.content,'html.parser')
    cve_page=dict()
    cve_exp_page=dict()
    for tr in soup.find_all('tr'):
        if re.search(r'SSV-(\d)+',str(tr)):
            tds=[td for td in tr.find_all('td')]
            ssv=tds[0].text
            date=tds[1].text
            title=tds[3].text
            status=tds[4].find_all('i')
            cve_id=re.search(r'(CVE-[\d]+-[\d]+)',str(status[0]))
            if cve_id:
                cid=cve_id.group(0)
                if " ".join(status[1].get('class'))=='fa fa-rocket text-muted ':
                    label=0
                elif " ".join(status[1].get('class'))=='fa fa-rocket ':
                    label=1
                    cve_exp_page[ssv]=(ssv,date,title,cid,label)
                else:
                    print("[!] WARNING poc_value is not 0 or 1")
            else:
                cid=''
                label=''
            cve_page[ssv]=(ssv,date,title,cid,label)
    return cve_page,cve_exp_page

def seebug_max_page(url='https://www.seebug.org/vuldb/vulnerabilities'):
    """
    获取seebug漏洞数据的最大页面数
    :return max_page:
        :type:int
        :value:N
    :return headers:
        :type:dict
        :value:浏览器头
    """
    headers=seebug_headers(url)
    if headers:
        print("[+] Bypassed Seebug Anti-Crawler")
    else:
        print("[!] Failed to Bypass Seebug Anti-Crawler")
    r=requests.get(url,headers=headers)
    regex=re.compile(r'page=(\d+)')
    num=re.findall(regex,r.text)
    num=[int(i) for i in num]
    max_page=max(num)
    print("[+] Got seebug vul max page:%d" %max_page)
    return max_page,headers

def seebug_exp_add():
    """
    爬取seebug全部ssv数据，返回增量cve exp数据
    :return seebug_exp_add:tuple_dict, cve added with exp data in seebug.org, e.g. {'SSV-18407': ('SSV-18407', '2002-05-19', 'psyBNC <= 2.3 Denial of Service Exploit', 'CVE-2002-0741', 1)}
    }
    """
    create_table(db='exp',table='seebug',key=['ssv','date','title','cid','label'],primary_key='ssv')
    so,exist_sid=cve_exists(db='exp',table='seebug',key=['ssv'])
    max_page,headers=seebug_max_page()
    # 对比本地数据和远程第一页数据
    seebug_ssv_add=dict()
    seebug_cve_exp_add=dict()
    for page in range(1,max_page):
        print("[+] Crawling seebug vul page:%d" %page)
        et=0
        vul_url='https://www.seebug.org/vuldb/vulnerabilities?page={}'.format(str(page))
        ssv_page,exp_page=seebug_page_parser(url=vul_url,headers=headers)
        # 判断单页和本地数据重复的数量
        ssv=list(ssv_page.values())
        for i in ssv:
            if i[0] in exist_sid:
                et=et+1
                del ssv_page[i[0]]
                if i[0] in list(exp_page.values()):
                    del exp_page[i[0]]
        
        # 判断是否需要插入数据库
        if et<20:
            seebug_ssv_add={**seebug_ssv_add,**ssv_page}
        else:
            pass
        seebug_cve_exp_add={**seebug_cve_exp_add,**exp_page}

        # 判断是否退出
        if et>0: 
            break
        else:
            pass
    if seebug_ssv_add:
        sql='replace INTO seebug (ssv,date,title,cid,label) VALUES (?, ?, ?, ?, ?)'
        so.executemany(sql,seebug_ssv_add.values())
    else:
        print("[!] Seebug updated not found")
    print('[+] Searched exp added from remote seebug.org')
    print('[+] Add ssv:%s' %seebug_cve_exp_add)
    return seebug_cve_exp_add

def seebug_exp_all():
    """
    从本地数据库中提取seebug.com所有有exp标记的cve
    :return exp_all:list, the whole cve id list with exp label from exploit-db.com, e.g. ['CVE-2020-11753', 'CVE-2019-8449']
    """
    so,exist_cid=cve_exists_where(db='exp',table='seebug',key=['cid'],where='label=1')
    print('[+] Searched all exp from local seebug db')

    return exist_cid

def securityfocus_exp():
    """
    security_focus exp label
    """
def symantic_exp():
    """
    symantic exp label
    """
def cve_in_the_wild():
    """
    cve exp label in the wild
    """

def exp_label(all_exp):
    """
    根据CVE id打标CVE_EXP_label字段
    :param all_exp: list
    """
    so=SQLite("data/cve.db")
    exps=dict()
    if all_exp:
        # 标记黑样本
        for i in all_exp:
            exps[i]=(1,i)
        sql='update nvd set CVE_EXP_label=? where CVE_Items_cve_CVE_data_meta_ID=?'
        so.executemany(sql,exps.values())
    else:
        print('[!] No exp be labeled')
    # 标记白样本
    sql='update nvd set CVE_EXP_label=0 where CVE_EXP_label=""'
    so.execute(sql)

def exp_5tuple(key,value):
    """
    返回EXP五元组列表，[(cve-id,description,cve publishedtime,cve modifiedtime or exp publishedtime,exp source)]
    """
    if not value:
        return []
    exps=[]
    for i in value.values():
        if key=='exploit-db':
            so,cve=cve_query_where(db='cve',table='nvd',key=['CVE_Items_cve_CVE_data_meta_ID','CVE_Items_cve_description_description_data_value','CVE_Items_publishedDate'],where='CVE_Items_cve_CVE_data_meta_ID = "{}"'.format(i[1]))
            if cve:
                exp=(cve[0][0],cve[0][1],cve[0][2],i[5],'https://www.exploit-db.com/exploits/'+i[0])
                exps.append(exp)
        elif key=='seebug':
            so,cve=cve_query_where(db='cve',table='nvd',key=['CVE_Items_cve_CVE_data_meta_ID','CVE_Items_cve_description_description_data_value','CVE_Items_publishedDate'],where='CVE_Items_cve_CVE_data_meta_ID = "{}"'.format(i[3]))
            if cve:
                exp=(cve[0][0],cve[0][1],cve[0][2],i[1],'https://www.seebug.org/vuldb/ssvid-'+i[0][4:])
                exps.append(exp)
        elif key=='github':
            so,cve=cve_query_where(db='cve',table='nvd',key=['CVE_Items_cve_CVE_data_meta_ID','CVE_Items_cve_description_description_data_value','CVE_Items_publishedDate'],where='CVE_Items_cve_CVE_data_meta_ID = "{}"'.format(i[0]))
            if cve:
                exp=(cve[0][0],cve[0][1],cve[0][2],i[1],i[2])
                exps.append(exp)
        else:
            pass
    return exps

def exp_table(exp5tuple):
    """
    将各个exp数据源的五元组统一插入一张表，todo fix: cve_id主键+replace出现问题
    """
    #create_table(db='exp',table='exps',key=['cve_id','description','cve_publishedtime','exp_publishedtime','exp_source'],primary_key='cve_id')
    so=SQLite('data/exp.db')
    sql="create table if not exists exps(cve_id TEXT,description TEXT,cve_publishedtime TEXT,exp_publishedtime TEXT,exp_source TEXT)"
    so.execute(sql)

    sql='replace INTO exps(cve_id,description,cve_publishedtime,exp_publishedtime,exp_source) VALUES (?, ?, ?, ?, ?)'
    so.executemany(sql,exp5tuple)

def exp_init():
    so=SQLite('data/exp.db')
    so.execute('delete from cvedetails')
    so.execute('delete from exploitdb')
    so.execute('delete from seebug')
    so.execute('delete from github')

    conf=configparser.ConfigParser()
    conf.read('conf/info.conf')
    conf.set('CVE_Label','total_count','0')
    with open('conf/info.conf', 'w') as configfile:
        conf.write(configfile)
    # cvedetails.com初始化
    cvedetails_crawler()
    # mitre:redownload
    mitre_expdb_all(reparse=True)
    # expdb:delete local sqlite3 table,then reparse=True
    expdb_exp_add(reparse=True)
    # seebug:delete local sqlite3 table,then add
    #seebug_exp_add()
    # github
    github_exp_add()

    # all->nvd
    exps=exp_all()
    exp_label(all_exp=exps)

def exp_add():
    """
    第三方数据源标记的exp每日和每月增量
    :return day_exp_add:tuple_list
    """
    # 日更新->exps&nvd：exploit-db.com、seebug、github
    a0=a1=a3=a4=a5=a6=list()
    a4=expdb_exp_add()
    a4=exp_5tuple(key='exploit-db',value=a4)
    #a5=seebug_exp_add()
    a5=exp_5tuple(key='seebug',value=a5)
    a6=github_exp_add()
    a6=exp_5tuple(key='github',value=a6)          
    day_exp_add=a0+a4+a5+a6
    exp_table(day_exp_add)
    cves=[i[0] for i in day_exp_add]
    exp_label(all_exp=cves)
    # 月更新->nvd：cvedetails.com、mitre
    month_day=time_delta(delta=-1,format='%Y-%m-%d')
    if month_day.split('-')[2]==30:
        a1=list(cvedetails_crawler().keys())
        a3=list(mitre_expdb_all(reparse=True).keys())
        month_exp_add=a0+a1+a3
        exp_label(all_exp=month_exp_add)

    return day_exp_add

def exp_query():
    """取第三方当天exp增量和当月exp增量
    """
    day=time_delta(delta=-1,format='%Y-%m-%d')
    so,exist_eid=cve_query_where(db='exp',table='exps',key=['*'],where='exp_publishedtime like "%{}%"'.format(day))

    month=time_delta(delta=-1,format='%Y-%m')
    so2,exist_eid2=cve_query_where(db='exp',table='exps',key=['*'],where='exp_publishedtime like "%{}%"'.format(month))

    return exist_eid,exist_eid2

def exp_all():
    """
    第三方数据源+nvd标记的exp所有数据
    :return all_exp:list
    """
    all_exp=l1=l2=l3=l4=l5=l6=[]
    exps=dict()
    l1=cvedetails_all()
    l2=nvd_nist_all()
    l3=list(mitre_expdb_all().keys())
    l4=expdb_exp_all()
    l5=seebug_exp_all()
    l6=github_exp_all()
    all_exp=all_exp+l1+l2+l3+l4+l5+l6
    all_exp=list(set(all_exp))
    
    exp_label(all_exp=all_exp)
    return all_exp

if __name__=='__main__':
    pass


    
    
    


